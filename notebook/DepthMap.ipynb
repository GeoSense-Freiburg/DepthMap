{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Map Estimation with Depth-Anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Depth Maps\n",
    "\n",
    "**Depth maps** are representations of the distance between the camera and objects in a scene. Each pixel in a depth map corresponds to the distance from the camera to that point in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing DepthAnything v2\n",
    "\n",
    "**DepthAnything** is a model that estimates depth from single RGB images using a teacher-student architecture with both labeled and unlabeled data.\n",
    "\n",
    "**How Does It Work?**\n",
    "\n",
    "                                          Labeled Data (1.5M images)\n",
    "                                                  ↓\n",
    "                                          Teacher Training \n",
    "                                                  ↓\n",
    "                           Unlabeled Data → Pseudo-labeling → Combined Dataset\n",
    "                            (62M images)                            ↓\n",
    "                                                     Student Training with Augmentations\n",
    "                                                                    ↓\n",
    "                                                               Final Model\n",
    "\n",
    "1. **Initial Training**\n",
    "   - Teacher model learns from 1.5M labeled depth images\n",
    "\n",
    "2. **Knowledge Transfer** \n",
    "   - Teacher labels 62M unlabeled images\n",
    "   - Student learns from both real and pseudo labels\n",
    "\n",
    "3. **Depth estimation**\n",
    "   - Takes regular RGB image\n",
    "   - Extracts visual features via encoder\n",
    "   - Decoder converts features to depth values\n",
    "   - Fine-tuned version for real-world depth measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the depth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /mnt/gsdata/users/kremer/DepthMap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "import cv2\n",
    "from typing import Any, Optional\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the working directory of this file\n",
    "working_dir = Path().resolve()\n",
    "root_dir = working_dir.parent\n",
    "print(f\"Project directory: {root_dir}\")\n",
    "\n",
    "# Add the DepthAnything directory to sys.path\n",
    "depth_anything_path = root_dir / 'models/Depth-Anything-V2/metric_depth'\n",
    "sys.path.append(str(depth_anything_path))\n",
    "from depth_anything_v2.dpt import DepthAnythingV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(depth_anything_path: Path, encoder: str = 'vitl', dataset: str = 'hypersim', max_depth: int = 20):\n",
    "    # Model configuration based on encoder\n",
    "    model_configs = {\n",
    "        'vits': {\n",
    "            'encoder': 'vits',\n",
    "            'features': 64,\n",
    "            'out_channels': [48, 96, 192, 384],\n",
    "        },\n",
    "        'vitb': {\n",
    "            'encoder': 'vitb',\n",
    "            'features': 128,\n",
    "            'out_channels': [96, 192, 384, 768],\n",
    "        },\n",
    "        'vitl': {\n",
    "            'encoder': 'vitl',\n",
    "            'features': 256,\n",
    "            'out_channels': [256, 512, 1024, 1024],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if encoder not in model_configs:\n",
    "        raise ValueError(f\"Unsupported encoder: {encoder}\")\n",
    "    \n",
    "    # Initialize the model with the specified configuration\n",
    "    model = DepthAnythingV2(**{**model_configs[encoder], 'max_depth': max_depth})\n",
    "    \n",
    "    # Load model checkpoint (model with pre-trained weights)\n",
    "    checkpoint = depth_anything_path / 'checkpoints' / f'depth_anything_v2_metric_{dataset}_{encoder}.pth'\n",
    "    if not checkpoint.exists():\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {checkpoint}\")\n",
    "    model.load_state_dict(torch.load(checkpoint, map_location='cpu'))\n",
    "    \n",
    "    # Determine device and move the model to it\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, device\n",
    "\n",
    "# Load the depth model\n",
    "model, device = load_model(depth_anything_path, encoder='vitl', dataset='hypersim', max_depth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth estimation on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_depth(model: Any, image_path: Path) -> Optional[np.ndarray]:\n",
    "    logging.info(f\"Estimating depth for {image_path}\")\n",
    "    \n",
    "    # Read the image from the given path\n",
    "    raw_img = cv2.imread(str(image_path))\n",
    "    if raw_img is None:\n",
    "        logging.error(f\"Failed to read image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    rgb_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Infer depth using the model\n",
    "    with torch.no_grad():\n",
    "        depth = model.infer_image(rgb_img)\n",
    "    \n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_depth_map(output_folder: Path, image_path: Path, depth_map: np.ndarray) -> Path:\n",
    "    # Create output paths and directories\n",
    "    stem = image_path.stem\n",
    "    depth_image_path = output_folder / \"images\" / f\"{stem}_depth.jpg\"\n",
    "    depth_array_path = output_folder / \"arrays\" / f\"{stem}_depth.npy\"\n",
    "    depth_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    depth_array_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save visualization (jpeg requires integer values)\n",
    "    normalized = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    colored = cv2.applyColorMap(normalized.astype(np.uint8), cv2.COLORMAP_VIRIDIS)\n",
    "    cv2.imwrite(str(depth_image_path), colored)\n",
    "    \n",
    "    # Save array (store as float32)\n",
    "    np.save(depth_array_path, depth_map)\n",
    "    \n",
    "    return depth_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(depth_map: np.ndarray) -> tuple:\n",
    "    quantile05 = np.percentile(depth_map, 5)\n",
    "    quantile95 = np.percentile(depth_map, 95)\n",
    "    mean = np.mean(depth_map)\n",
    "    median = np.median(depth_map)\n",
    "    return quantile05, quantile95, mean, median\n",
    "\n",
    "def write_csv(csv_path: Path, data: list, headers: Optional[list] = None):\n",
    "    # Append data to CSV\n",
    "    file_exists = csv_path.exists()\n",
    "    with csv_path.open('a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if headers and not file_exists:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerow(data)\n",
    "\n",
    "def process_images(model: Any, input_folder: Path, output_folder: Path, csv_path: Path):\n",
    "    # Check if all required paths are provided\n",
    "    if not input_folder or not output_folder or not csv_path:\n",
    "        raise ValueError(\"All paths (input_folder, output_folder, csv_path) must be provided\")\n",
    "    \n",
    "    # Check if input folder exists\n",
    "    if not input_folder.exists():\n",
    "        raise FileNotFoundError(f\"Input folder does not exist: {input_folder}\")\n",
    "    \n",
    "    if not input_folder.is_dir():\n",
    "        raise NotADirectoryError(f\"Input path is not a directory: {input_folder}\")\n",
    "    \n",
    "    print(f\"Processing images from {input_folder}\")\n",
    "    images = [p for p in Path(input_folder).rglob('*') if p.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']]\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    headers = ['filename', 'Quantile05', 'Quantile95', 'Mean', 'Median']\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in images:\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"::: Estimating depth for {img_path} :::\")\n",
    "        depth = infer_depth(model, img_path)\n",
    "        \n",
    "        if depth is None:\n",
    "            continue\n",
    "        \n",
    "        print(f\"::: Computing statistics and saving depth map :::\")\n",
    "        q05, q95, mean, median = compute_statistics(depth)\n",
    "        write_csv(csv_path, [img_path.name, q05, q95, mean, median], headers=headers)\n",
    "        depth_image_path = save_depth_map(output_folder, img_path, depth)\n",
    "        print(f\"Processed {img_path.name} -> Saved Depth Map at {depth_image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images from /mnt/gsdata/users/kremer/DepthMap/test/images\n",
      "----------------------------------------------------------------------------------------------------\n",
      "::: Estimating depth for /mnt/gsdata/users/kremer/DepthMap/test/images/G5Bullet_56_2024-10-09_01_21_00_calibrated.jpg :::\n",
      "::: Computing statistics and saving depth map :::\n",
      "Processed G5Bullet_56_2024-10-09_01_21_00_calibrated.jpg -> Saved Depth Map at /mnt/gsdata/users/kremer/DepthMap/test/output/depth_map/images/G5Bullet_56_2024-10-09_01_21_00_calibrated_depth.jpg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "::: Estimating depth for /mnt/gsdata/users/kremer/DepthMap/test/images/G5Bullet_55_2024-10-08_01_36_00_calibrated.jpg :::\n",
      "::: Computing statistics and saving depth map :::\n",
      "Processed G5Bullet_55_2024-10-08_01_36_00_calibrated.jpg -> Saved Depth Map at /mnt/gsdata/users/kremer/DepthMap/test/output/depth_map/images/G5Bullet_55_2024-10-08_01_36_00_calibrated_depth.jpg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "::: Estimating depth for /mnt/gsdata/users/kremer/DepthMap/test/images/G5Bullet_56_2024-10-09_13_18_00_calibrated.jpg :::\n",
      "::: Computing statistics and saving depth map :::\n",
      "Processed G5Bullet_56_2024-10-09_13_18_00_calibrated.jpg -> Saved Depth Map at /mnt/gsdata/users/kremer/DepthMap/test/output/depth_map/images/G5Bullet_56_2024-10-09_13_18_00_calibrated_depth.jpg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "::: Estimating depth for /mnt/gsdata/users/kremer/DepthMap/test/images/G5Bullet_55_2024-10-08_12_42_00_calibrated.jpg :::\n",
      "::: Computing statistics and saving depth map :::\n",
      "Processed G5Bullet_55_2024-10-08_12_42_00_calibrated.jpg -> Saved Depth Map at /mnt/gsdata/users/kremer/DepthMap/test/output/depth_map/images/G5Bullet_55_2024-10-08_12_42_00_calibrated_depth.jpg\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories (change as needed)\n",
    "input_folder = root_dir / 'test/images/'\n",
    "output_folder = root_dir / 'test/output/depth_map/'\n",
    "csv_file_path = root_dir / 'test/output/depth_map/depth.csv'\n",
    "\n",
    "# Process all images in the input directory\n",
    "process_images(model, input_folder, output_folder, csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depthmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
